<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="">
  <meta name="keywords" content="Partial Non-isometric Deformations with soft constrained Jacobian Fields">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>ScanTalk</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script> -->
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/icon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <!-- <h1 class="title is-1 publication-title">ECCV 2024</h1>-->
          <h1 class="title is-1 publication-title">ScanTalk: 3D Talking Heads from Unregistered Scans</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://fedenoce.github.io/">Federico Nocentini</a><sup>1,*</sup>,</span>
            <span class="author-block">
                <a href="https://tbesnier.github.io/">Thomas Besnier</a><sup>2,*</sup>,</span>
            <span class="author-block">
                <a href="https://clferrari.github.io/">Claudio Ferrari</a><sup>4</sup>,</span>
            <span class="author-block">
                <a href="https://dblp.org/pid/161/6737.html">Sylvain Arguillere</a><sup>5</sup>,</span>
            <span class="author-block">
                <a href="https://scholar.google.com/citations?user=3GPTAGQAAAAJ&hl=en">Stefano Berretti</a><sup>1</sup>,</span>
            <span class="author-block">
                <a href="https://sites.google.com/view/mohameddaoudi">Mohamed Daoudi</a><sup>2,3</sup>.</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Media Integration and Communication Center (MICC), University of Florence, Italy,</span>
            <span class="author-block"><sup>2</sup>Univ. Lille, CNRS, Centrale Lille, UMR 9189 CRIStAL, F-59000 Lille, France,</span>
            <span class="author-block"><sup>3</sup>IMT Nord Europe, Institut Mines-Télécom, Centre for Digital Systems,</span>
            <span class="author-block"><sup>4</sup>Department of Architecture and Engineering University of Parma, Italy,</span>
            <span class="author-block"><sup>5</sup>Univ. Lille, CNRS, UMR 8524 Laboratoire Paul Painlevé, Lille, F-59000, France,</span>
            <span class="author-block"><sup>*</sup>Equal Contribution.</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2403.10942"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. 
              <span class="link-block">
                <a href="#teaser"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://github.com/miccunifi/ScanTalk/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Proposed Method. -->
<section class="section">
<div class="columns is-centered has-text-centered">
  <div class="column is-four-fifths">
    <div class="content has-text-justified">
      <img src="./static/videos/scantalk_idea.png" alt="scantalk_idea">
      <p>
        <br>
        We present <strong>ScanTalk</strong>, a deep learning architecture to animate <strong>any</strong> 3D face
        mesh driven by a speech. ScanTalk is robust enough to learn on multiple unrelated
        datasets with a unique model, whilst allowing us to infer on unregistered face meshes.

      </p>
      <!-- <p>
        
      </p>
      <p>
        
      </p> -->
    </div>
  </div>
</div>
</section>


<!--/ Proposed Method. -->  
<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Speech-driven 3D talking heads generation has emerged as a significant area of interest among researchers, 
            presenting numerous challenges. Existing methods are constrained by animating faces with fixed topologies, 
            wherein point-wise correspondence is established, 
            and the number and order of points remains consistent across all identities the model can animate. 
            <br>
            <br>
            In this work, we present ScanTalk, a novel framework capable of animating 3D 
            faces in arbitrary topologies including scanned data. Our approach relies on 
            the DiffusionNet architecture to overcome the fixed topology constraint, offering 
            promising avenues for more flexible and realistic 3D animations. By leveraging the power of DiffusionNet, 
            ScanTalk not only adapts to diverse facial structures but also maintains fidelity when dealing with scanned data, 
            thereby enhancing the authenticity and versatility of generated 3D talking heads. Through comprehensive comparisons 
            with state-of-the-art methods, we validate the efficacy of our approach, demonstrating its capacity to generate realistic 
            talking heads comparable to existing techniques. While our primary objective is to develop a generic method free from 
            topological constraints, all state-of-the-art methodologies are bound by such limitations.


          </p>
        </div>
      </div>
    </div>
    <br>
    <br>
    
    <!-- Proposed Method. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 centered-title">Proposed Method</h2>
        <div class="content has-text-justified">
          <img src="./static/videos/scantalk.png" alt="scantalk">
          <p>
            <br>
            Architecture of <strong>ScanTalk</strong> A novel Encoder-Decoder framework designed to dynamically animate any
             3D face based on a spoken sentence from an audio file. The Encoder integrates the 3D neutral face, per-vertex 
             surface features (crucial for DiffusionNet and precomputed by the operators OP), 
            and the audio file, yielding a fusion of per-vertex and audio features. 
          These combined descriptors, alongside per-vertex 
          surface features, are then passed to the Decoder, which mirrors a reversed
           DiffusionNet encoder structure. The Decoder predicts the deformation of the 3D neutral face, which is then 
           combined with the original 3D neutral face to generate the animated sequence.

          </p>
          <!-- <p>
            
          </p>
          <p>
            
          </p> -->
        </div>
      </div>
    </div>
    <!--/ Proposed Method. -->  
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <h2 class="title is-3 centered-title">Intro Video</h2>
    <div class="hero-body">
      <video id="teaser" controls playsinline height="100%">
        <source src="./static/videos/ScanTalk_Intro.mp4"
                type="video/mp4">
      </video>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <h2 class="title is-3 centered-title">Qualitative Examples</h2>
    
    <!-- First row of videos -->
    <div class="hero-body video-row">
      <video id="teaser1" class="video-item" controls playsinline>
        <source src="./static/videos/Thanos_20s.mp4" type="video/mp4">
      </video>
      <video id="teaser2" class="video-item" controls playsinline>
        <source src="./static/videos/test_arnold_shrek.mp4" type="video/mp4">
      </video>
      <video id="teaser3" class="video-item" controls playsinline>
        <source src="./static/videos/test_thanks_long.mp4" type="video/mp4">
      </video>
    </div>
    
    <!-- Second row of videos -->
    <div class="hero-body video-row">
      <video id="teaser4" class="video-item" controls playsinline>
        <source src="./static/videos/VOCA_rock.mp4" type="video/mp4">
      </video>
      <video id="teaser5" class="video-item" controls playsinline>
        <source src="./static/videos/Anime_Cold_Dip.mp4" type="video/mp4">
      </video>
      <video id="teaser6" class="video-item" controls playsinline>
        <source src="./static/videos/BIWI_photo.mp4" type="video/mp4">
      </video>
    </div>
  </div>
</section>






<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
  @inproceedings{nocentini2024scantalk3dtalkingheads,
    title = {ScanTalk: 3D Talking Heads from Unregistered Scans},
    author = {Nocentini, F. and Besnier, T. and Ferrari, C. and Arguillere, S. and Berretti, S. and Daoudi, M.},
    booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
    year = {2024},
  }
</code></pre>
  </div>
</section>
 



<footer class="footer">
  <div class="container">
      <div class="content has-text-centered">
          <a class="icon-link" href="./media/scantalk.pdf">
              <i class="fas fa-file-pdf"></i>
          </a>
          <a class="icon-link" href="https://github.com/miccunifi/ScanTalk/" class="external-link" disabled>
              <i class="fab fa-github"></i>
          </a>
      </div>
      <div class="columns is-centered">
          <div class="column is-8">
              <div class="content">
                  <p style="text-align:center">
                    This website is licensed under a <a rel="license"
                    href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                    Commons Attribution-ShareAlike 4.0 International License</a>.
                  </p>
                  <p style="text-align:center">
                    Website source code based on the <a
                    href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> project page.
                  </p>

              </div>
          </div>
      </div>
  </div>
</footer>

</body>
</html>
